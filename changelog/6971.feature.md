Incremental training of models in a pipeline is now supported.

If you have added new NLU training examples or new stories/rules for  
dialogue manager, you don't need to train the pipeline from scratch.
Instead, you can initialize the pipeline with a previously trained model
and continue finetuning the model on the complete dataset consisting of
new training examples. To do so, use `rasa train --finetune`. For more
detailed explanation of the command, check out the docs on [incremental  
training](./command-line-interface.mdx#incremental-training).

Added a configuration parameter `additional_vocabulary_size` to  
[`CountVectorsFeaturizer`](./components.mdx#countvectorsfeaturizer)  
and `number_additional_patterns` to [`RegexFeaturizer`](./components.mdx#regexfeaturizer).
These parameters are useful to configure when using incremental training for your pipelines.