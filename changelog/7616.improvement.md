Added sigmoid cross-entropy loss on all similarity values to constrain them to an approximate range in `DotProductLoss`.

This affects the default behaviour of the loss function(`loss_type=cross_entropy`) inside machine learning (ML) components - `DIETClassifier`, `ResponseSelector` and `TEDPolicy`.
If you notice a degradation in performance, set `constrain_similarities=False` in the respective ML component.
You should tune fallback confidence thresholds to adapt to this change.

Configuration option `loss_type=softmax` is now deprecated. Use `loss_type=cross_entropy` instead.

Also, added an option `model_confidence` to each ML component. It affects how model's confidence for each label is computed during inference. It can take three values -
1. `softmax` - Similarities between input and label embeddings are post-processed with a softmax function, as a result of which confidence for all labels sum up to 1.
2. `cosine` - Cosine similarity between input label embeddings. Confidence for each label is in the range `[-1,1]`.
3. `inner` - Dot product similarity between input and label embeddings. Confidence for each label in in an unbounded range.

The default value is `softmax`, but we recommend using `cosine` as that will be the default value, Rasa Open Source 3.0 onwards. The value of this option does not affect how confidences are computed for entity predictions in `DIETClassifier` and `TEDPolicy`.
