---
id: contextual-conversations
sidebar_label: Contextual Conversations
title: Contextual Conversations
---

To create a context-aware conversational assistant, you will need to define
how your assistant uses the conversation history to affect the next response.

For example, if a user asks Sara, the Rasa bot, how to get started using Rasa,
Sara gives the user
different information based on whether they've built an AI assistant before or not:

A conversation with a new user:
```yaml
User: How can I get started with Rasa?
    Sara: To determine how I can help you best, I'm going to ask you a few questions.
    Sara: Let's go. Are you new to Rasa?
User: yes
    Sara: And have you built a contextual assistant or a bot before?
```

A conversation with a returning user:
```yaml
User: How can I get started with Rasa?
    Sara: To determine how I can help you best, I'm going to ask you a few questions.
    Sara: Let's go. Are you new to Rasa?
User: no
    Sara: Ok, which product would you like to know more about? Rasa Open Source or Rasa X?
```

This page is a guide on creating contextual conversation patterns using Rasa.

## Contextual Conversation Patterns

### 1. Creating Stories

[Stories](./stories.mdx) are examples of how conversations should go. In order for Sara to respond differently for new users
and users with previous experience, you'd need stories like this:


```yaml
stories:
  - story: New user
    steps:
  - intent: how_to_get_started
  - action: utter_getstarted
  - action: utter_first_bot_with_rasa
  - intent: affirm
  - action: action_set_onboarding
  - slot_was_set:
    - onboarding: true
  - action: utter_built_bot_before

  - story: Not new user
    steps:
  - intent: how_to_get_started
  - action: utter_getstarted
  - action: utter_first_bot_with_rasa
  - intent: deny
  - action: action_set_onboarding
  - slot_was_set:
    - onboarding: false
  - action: utter_ask_which_product
```

These stories diverge based on the users intent (`affirm` or `deny`). Using
on the user's intent, an action sets a slot that further directs
the conversation.

### 2. Defining Slots

[Slots](domain.mdx#slots) are your assistant's memory. Slots store pieces of information that your
assistant needs to refer to later and can direct the flow of the conversation
based on `slot_was_set` events. There are different [types of slots](domain.mdx#slot-types),
and each affects the conversation flow in its own way.

In the getting started example, the `onboarding` slot is a boolean slot. If it is true, the
user is treated as a new user, and if it is false, as a user with previous bot building experience.
You define a slot and its type in the domain:

```rasa-yaml
slots:
  onboarding:
    type: bool
```

### 3. Configuring the TEDPolicy

In addition to adding stories to account for context,
machine learning policies can help your model generalize
to unseen conversation paths. **It is important
to understand that using machine-learning policies does not mean letting go of control over your
assistant.** If a rule based policy is able to make a prediction, that prediction will
always have a higher priority (read more [here](./policies.mdx#action-selection)) and predict the next action.

The [TEDPolicy](https://blog.rasa.com/unpacking-the-ted-policy-in-rasa-open-source/) is made to handle
unexpected user behaviors. For example,
in the conversation below (extracted from a conversation on [Rasa X](https://rasa.com/docs/rasa-x/user-guide/review-conversations/)):

```rasa-yaml
stories:
- story: Story from conversation with a2baab6c83054bfaa8d598459c659d2a on November 28th 2019
  steps:
  - checkpoint: STORY_START
  - intent: greet
  - action: action_greet_user
  - slot_was_set:
    - shown_privacy: true
  - intent: ask_whoisit
  - action: action_chitchat
  - intent: ask_whatspossible
  - action: action_chitchat
  - intent: telljoke
  - action: action_chitchat
  - intent: how_to_get_started
    entities:
    - product: x
  - slot_was_set:
    - product: x
  - action: utter_explain_x
  - action: utter_also_explain_nlucore
  - intent: affirm
  - action: utter_explain_nlu
  - action: utter_explain_core
  - action: utter_direct_to_step2
```

Here we can see the user has completed a few chitchat tasks first, and then ultimately
asks how they can get started with Rasa X. The TEDPolicy correctly predicts that
Rasa X should be explained to the user, and then also takes them down the getting started
path, without asking all the qualifying questions first.

Because the machine-learning policy has generalized to this situation, you should add this story
to your training data to continuously improve your bot and help the model generalize
better in future. [Rasa X](https://rasa.com/docs/rasa-x/) is a tool that can help
you improve your bot and make it more contextual.


#### Setting `max_history`

Usually, only a certain amount of context is relevant to your assistant.
[`max_history`](policies.mdx#max-history) is a hyperparameter for Rasa dialogue management policies
that controls how much dialogue history the model looks at to decide which
action to take next.

You can set the `max_history` by passing it to your policy's Featurizer
in the policy configuration yaml file, for example:

```
policies:
  - name: "TEDPolicy"
    featurizer:
    - name: MaxHistoryTrackerFeaturizer
      max_history: 5
```

You want to make sure `max_history` is set high enough
to account for the most context your assistant will need to make an accurate
prediction about what to do next.
For more details see the docs on [conversation featurization](policies.mdx#conversationfeaturization).

### 4. Using Real Conversations as Stories

It's difficult to know ahead of time exactly which conversation
contexts the bot will encounter since your users will probably take conversation paths you didn't expect.
One of the best ways to improve your assistant's contextual skills
is to take real conversations as training data, after correcting where
the bot went wrong if necessary. When doing so, pay attention
to slot and entity values and make sure to [test your assistant](testing-your-assistant.mdx)
thoroughly to make sure your changes don't introduce regressions.

## Summary

Here's a summary of the concepts you can apply to enable your assistant to have contextual conversations:

- [ ] Write [stories](#stories) for contextual conversations
- [ ] Use [slots](#slots) to store contextual information for later use
- [ ] Set the [`max_history`](#max_history) for your policies appropriately for the amount of context your bot needs
- [ ] Use the [TEDPolicy](#tedpolicy) for generalization to unseen conversation paths
- [ ] [`Save real conversations as stories`](#save-real-conversations-as-stories) to enhance your bot's contextual abilities
