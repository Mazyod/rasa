---
id: fallback-handoff
sidebar_label: Fallback and Human Handoff
title: Fallback and Human Handoff
abstract: When conversational assistants fail, it's important that they do so gracefully.
---

import useBaseUrl from '@docusaurus/useBaseUrl';


Even if you design your bot perfectly, users will inevitably say things to your
assistant that you did not anticipate. In these cases, your assistant will fail,
and it's important you ensure it does so gracefully.

## Handling Out-of-Scope Messages

It is good practice to handle questions you know your users may ask,
but for which you haven't implemented a user goal yet.

You can define an `out_of_scope` intent to handle generic out of scope requests, like “I'm hungry” and have
the bot respond with a default message like “Sorry, I can't handle that request” by writing a rule with the
`out_of_scope` intent in it.


### 1. Creating an Out-of-Scope intent

You will first need to define an `out_of_scope` intent in your NLU training data and add any known
out-of-scope requests as training examples, for example:

```yaml
nlu:
- intent: out_of_scope
  examples: |
    - I want to order food
    - What is 2 + 2?
    - Who's the US President?
```

As with every intent, you should source the majority of your examples
from real conversations. This is especially important for out-of-scope intents
since false positives for these intents can lead to a bad user experience.


### 2. Defining the response message

You'll need to define an out-of-scope response in the domain file.
Using the utterance `utter_out_of_scope` as the default response, that would look like:

```yaml
responses:
  utter_out_of_scope:
  - text: Sorry, I can't handle that request.
```

### 3. Creating an Out-of-Scope Rule

Finally, you will need to write a rule for what should happen for in out-of-scope request:

```yaml
rules:
- rule: out of scope
  steps:
  - intent: out_of_scope
  - action: utter_out_of_scope
```

### Handling Specific Out-Of-Scope Messages

If you observe your users asking for certain things that you'll
want to turn into a user goal in future, you can handle these as separate intents, to let
the user know you've understood their message, but don't have a solution quite yet. For example,
if the user asks “I want to apply for a job at Rasa”, we can then reply with
“I understand you're looking for a job, but I'm afraid I can't handle that skill yet.”

Similar to the `out_of_scope` intent example, you'll need to create a new intent with
training examples, define the response message, and create a rule.


## Fallbacks

Although Rasa's [Intent Classifier](./components.mdx#intent-classifiers) will
generalize to unseen messages, some
messages might receive a low classification confidence. Using Fallbacks will
help ensure that these low confidence messages are handled gracefully, giving your
assistant the option to either respond with a default message or attempt to disambiguate
the user input.


### NLU Fallback

To handle incoming messages with low NLU confidence, we recommend adding the
[FallbackClassifier](./components.mdx#fallbackclassifier) to your NLU pipeline.
Using this configuration, the intent `nlu_fallback` will be predicted when all other intent
predictions fall below the configured confidence threshold. You can then write a rule
for what the bot should do when `nlu_fallback` is predicted.

#### 1. Updating the configuration

```yaml
pipeline:
# other components
- name: FallbackClassifier
  confidence_threshold: 0.7
```

#### 2. Defining the response message

```yaml
responses:
  utter_please_rephrase:
  - text: I'm sorry, I didn't quite understand that. Could you rephrase?
```

#### 3. Creating an NLU fallback rule

The following
[Rule](./rules.mdx) will ask the user to rephrase when they send a message that is
classified with low confidence:

```yaml
rules:
- rule: Ask the user to rephrase whenever they send a message with low NLU confidence
  steps:
  - intent: nlu_fallback
  - action: utter_please_rephrase
```


### Handling Low Core Confidence

As users might send unexpected messages,
it is possible that their behavior will lead them down unknown conversation paths.
Rasa's machine learning policies such as the [TED Policy](./policies.mdx#ted-policy)
are optimized to handle these unknown paths.

To handle cases when the machine learning policies can't predict the
next action with high confidence, you can configure the
[Rule Policy](./policies.mdx#rule-policy) to predict a
default action if no [Policy](./policies.mdx) has a next action prediction with
confidence above a configurable threshold.

You can configure the action that is run in case low confidence as well as
the corresponding confidence threshold using the following steps:


#### 1. Updating the configuration

```yaml
policies:
- name: RulePolicy
  # Confidence threshold for the `core_fallback_action_name` to apply.
  # The action will apply if no other action was predicted with
  # a confidence >= core_fallback_threshold
  core_fallback_threshold: 0.4
  core_fallback_action_name: "action_default_fallback"
  enable_fallback_prediction: True
```

:::note
If you do not want the `Rule Policy` to predict a default action in case of low Core
confidence, specify `enable_fallback_prediction: False` in the configuration of the
policy.
:::


#### 2. Defining the default response message

By default, Rasa Open Source will send the `utter_default` response to the user when
the action confidence falls below the configured threshold. Make sure to specify
the `utter_default` in your domain file. It will also revert back to the
state of the conversation before the user message that caused the
fallback, so it will not influence the prediction of future actions.

`utter_default` can be defined in your domain file as:

```yaml
responses:
  utter_default:
  - text: Sorry I didn't get that. Can you rephrase?
```

#### 3. Customizing the default action (optional)

`action_default_fallback` is a default action in Rasa Open Source that sends the
`utter_default` response to the user. You can create your own custom action to use as a
fallback (see [Custom Actions](./actions.mdx#custom-actions) for more info on custom actions).
The following snippet is an implementation of a custom action which does the same as
`action_default_fallback` but dispatches a different template
`my_custom_fallback_template`:

```python
from typing import Any, Text, Dict, List

from rasa_sdk import Action, Tracker
from rasa_sdk.events import UserUtteranceReverted
from rasa_sdk.executor import CollectingDispatcher

class ActionDefaultFallback(Action):
    """Executes the fallback action and goes back to the previous state
    of the dialogue"""

    def name(self) -> Text:
        return ACTION_DEFAULT_FALLBACK_NAME

    async def run(
        self,
        dispatcher: CollectingDispatcher,
        tracker: Tracker,
        domain: Dict[Text, Any],
    ) -> List[Dict[Text, Any]]:
        dispatcher.utter_message(template="my_custom_fallback_template")

        # Revert user message which led to fallback.
        return [UserUtteranceReverted()]
```


<img alt="Intent Mappings" src={useBaseUrl("/img/intent_mappings.png")} width="240" />



### Two-Stage Fallback

In some cases, you will want to attempt to disambiguate the user's message by asking
clarifying questions. The Two-Stage Fallback is made to handle low NLU confidence in multiple stages
using the following sequence:

- If an NLU prediction has a low confidence score, the user is asked to affirm
  the classification of the intent.  (Default action:
  `action_default_ask_affirmation`)

    - If they affirm by sending a message with high NLU confidence (e.g. by pressing
      a button), the story continues as if the intent was classified
      with high confidence from the beginning.
    - If they deny by sending a message with the intent `out_of_scope`, the user is
      asked to rephrase their message.

- Rephrasing  (default action: `action_default_ask_rephrase`)

    - If the classification of the rephrased intent was confident, the story
      continues as if the user had this intent from the beginning.
    - If the rephrased intent was not classified with high confidence, the user
      is asked to affirm the classified intent.

- Second affirmation  (default action: `action_default_ask_affirmation`)

    - If they affirm by sending a message with high NLU confidence (e.g. by pressing
      a button), the story continues as if the user had this intent from the beginning.
    - If the user denies by sending a message with the intent `out_of_scope`, the
      original intent is classified as the specifies `deny_suggestion_intent_name`,
      and an ultimate fallback action `fallback_nlu_action_name` is
      triggered (e.g. a handoff to a human).


The Two-Stage-Fallback can be enabled using the following steps:

#### 1. Updating the configuration

Add FallbackClassifier to your pipeline and the [RulePolicy](./policies.mdx#rule-policy)
to your policy configuration:

```yaml
pipeline:
# other components
- name: FallbackClassifier
  confidence_threshold: 0.7

policies:
# other policies
- RulePolicy
```


#### 2. Defining the fallback responses

Rasa Open Source provides default implementations for
`action_default_ask_affirmation` and `action_default_ask_rephrase`.
The default implementation of `action_default_ask_rephrase` utters
the response `utter_ask_rephrase`, so make sure to specify this
response in your domain file:

```yaml
responses:
  utter_ask_rephrase:
  - text: I'm sorry, I didn't quite understand that. Could you rephrase?
```

:::note
The implementations of `action_default_ask_affirmation` and `action_default_ask_rephrase`
can be overwritten using [Custom Actions](./actions.mdx#custom-actions).
:::

#### 3. Defining a Two-Stage Fallback rule

Add the following [Rule](./rules.mdx) to your training data. This rule will make sure
that the Two-Stage-Fallback will be activated whenever a message is received with
low classification confidence.

```yaml
rules:
- rule: Implementation of the Two-Stage-Fallback
  steps:
  - intent: nlu_fallback
  - action: two_stage_fallback
  - form: two_stage_fallback
```


## Human Handoff

As part of your fallback action, you may want the bot to hand over to a human agent
e.g. as the final action in Two-Stage-Fallback, or when the user explicitly asks
for a human. A straightforward way to achieve human handoff is to configure your
[messaging or voice channel](messaging-and-voice-channels.mdx) to switch
which host it listens to based on a specific bot or user message.

For example, as the final action of Two-Stage-Fallback, the bot could ask the user,
"Would you like to be transferred to a human assistant?" and if they say yes, the
bot sends a message with a specific payload like
e.g. "handoff_to_human" to the channel. When the channel sees this message, it stops listening
to the Rasa server, and sends a message to the human channel with the transcript
of the chat conversation up to that point.

The implementation for handing off to a human from the front end will depend on which
channel you're using. You can
see an example implementation using an adaption of the [chatroom](https://github.com/scalableminds/chatroom) channel
in the [Financial Demo](https://github.com/RasaHQ/financial-demo) and
[Helpdesk-Assistant](https://github.com/RasaHQ/helpdesk-assistant)
starterpacks.



## Summary

It's up to you how you want your assistant to act in a fallback or handoff
situation. You might want to use one or more of the options
described above. Here's a summary of changes you need to make for each:

For known out-of-scope intents:
  - [ ] Add training examples for each out-of-scope intent to your NLU data
  - [ ] Define the out-of-scope response or action
  - [ ] Define rules for each out-of-scope intent

For single stage NLU fallback:
  - [ ] Add FallbackClassifier to your pipeline in `config.yml`
  - [ ] Define the fallback response or action
  - [ ] Define a rule for the `nlu_fallback` intent

For handling low core confidence:
  - [ ] Configure the RulePolicy for core fallback in `config.yml`
  - [ ] Optionally customize the fallback action you configure

For Two-Stage Fallback:
  - [ ] Add FallbackClassifier to your pipeline in `config.yml`
  - [ ] Define a rule for the `nlu_fallback` intent that triggers the `two_stage_fallback` action
  - [ ] Define an out-of-scope intent in your domain

For handing off to a human:
  - [ ] Configure your front end to switch hosts
  - [ ] Write a custom action (which could be your fallback action) to send the handoff payload
  - [ ] Add a rule for triggering handoff (if not part of fallback)
