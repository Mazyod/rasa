---
id: training-data-format
sidebar_label: Training Data Format
title: Training Data Format
description: Description of the YAML format for training data
---

## Overview

### YAML Format

Rasa Open Source 2.0 uses [YAML](https://yaml.org/spec/1.2/spec.html) as
a unified and extendable way to manage all kinds of training data,
including NLU data, stories, and responses. With the YAML format, users
are free to distribute training data among any number of YAML files;
only the top level keys determine what kind of training data is in a
section. That means that if any one component of training data gets too
large (e.g. a lookup table with many entries), it can be moved to a
separate file.

### High Level Structure

Each file can contain one or more **keys** with corresponding training
data. One file can contain multiple keys, as long as there is not more
than one of a certain key in a single file. The available keys are:

-   `version`
-   `stories`
-   `nlu`
-   `responses`
-   `rules`
-   `e2e_tests`

All YAML training data files should specify the `version` key in order
to be parsed correctly:

-   Training data files with no `version` specified will be assumed to
    be in the format of the latest version of Rasa Open Source.
-   Training data files with a version greater than is currently
    available for Rasa Open Source will be skipped.

### Example

Here's a short example which keeps all training data in a single file:

```yaml
version: "2.0"

stories:
- story: greet and faq
  steps:
  - intent: greet
  - action: utter_greet
  - intent: faq
  - action: respond_faq

rules:
- rule: Greet user
  steps:
  - intent: greet
  - action: utter_greet

responses:
  faq/language:
  - text: |
    I can only do English at the moment

  utter_greet:
  - text: |
    Hallo there!

nlu:
- intent: greet
  examples: |
  - Hallo
  - Hi

- intent: faq/language
  examples: |
  - What language do you speak?
  - Do you only handle english?

e2e_tests:
- user: |
    hello
  intent: greet
- action: utter_greet
- user: |
    what language do you speak
  intent: faq/language
- action: respond_faq
```


## NLU Training Data

NLU training data consists of example user utterances categorized by
**intent**, i.e. what the user is trying to convey or accomplish with their
message. Training examples can also include **entities**, which is structured
information that can be extracted from a user's message. The other components
of NLU training data are there to help the model identify intent and entity
correctly.

NLU training data is defined under the `nlu` key. Items that can be added under this key are:

- [Training examples](#training-examples) grouped by user intent,
  optionally with annotated [entities](#entities)
- [Synonyms](#synonyms)
- [Regular Expression Features](#regular-expression-features)
- [Lookup Tables](#lookup-tables)

Here is a simple example of each item type:

```yaml
nlu:
- intent: greet
  examples: |
  - hey
  - hello

- synonym: credit
  examples: |
  - credit card account
  - credit account

- regex: zipcode
  examples: |
  - [0-9]{5}

- lookup: additional_currencies
  examples: |
  - Peso
  - Euro
  - Dollar
```


### Training Examples

Training examples are grouped by intent and listed under the
`examples` key. Examples can be provided in one of two formats:

1.  As a list of text values. For example:

```yaml
nlu:
- intent: greet
  examples: |
  - hey
  - hallo
  - whats up
```

1.  As a list of dictionaries, with at least the `text` key specified.
    For example:

```yaml
nlu:
- intent: greet
  examples: 
  - text: |
      hallo
    metadata:
      sentiment: neutral
  - text: |
      hey there!
```

Note the `metadata` key inside the `examples` dictionary. It can contain arbitrary key-value data and the parser will not read its value. You can use it to store
any information relevant to the example.

### Entities

Where applicable, entites are annotated in training examples using the
syntax:

```yaml
[<entity-text>]{"entity": "<entity name>"}
```

In a training example, this would look like:

```yaml
nlu:
- intent: check_balance
  examples: |
  - how much do I have on my [savings]{"entity": "account"} account
  - how much money is in my [checking]{"entity": "account"} account
```

You can also assign synonyms, roles, or groups to an entity using the
syntax:

```yaml
[<entity-text>]{"entity": "<entity name>", "role": "<role name>", "group": "<group name>", "value": "<entity synonym>"}
```

The keywords `role`, `group`, and `value` are optional in this notation.
The `value` keyword refers to synonyms, which are explained in the
following section. To understand what the labels `role` and `group` are
for, see section entities-roles-groups.

### Synonyms

Synonyms provide a way to normalize your training data by mapping an
extracted entity to a value other than the literal text extracted.
Synonyms can be defined in the format:

```yaml
- synonym: <synonym value>
  examples: |
  - <a synonym variation>
  - <another synonym variation>
```

Synonyms can also be definedin-line in your training examples by
specifying the `value` of the entity:

```yaml
nlu:
- intent: check_balance
  examples: |
  - how much do I have on my [credit card account]{"entity": "account", "value": "credit"}
  - how much do I owe on my [credit account]{"entity": "account", "value": "credit"}
```

To use the synonyms defined in your training data, you need to make sure the
pipeline contains the `EntitySynonymMapper` component (see components). You
should define synonyms when there are multiple ways users refer to the same
thing.

For example, let's say you had an entity `account_type`, and you expect the
value "credit". Your users also refer to their "credit" account as "credit
account" and "credit card account".

In this case, you could define "credit card account" and "credit account" as
**synonyms** to "credit":

```yaml
- synonym: credit
  examples: |
  - credit card account
  - credit account
```

Then, if either of these phrases is extracted as an entity, it will be
mapped to the **value** `credit`.

:::note
Synonym mapping only happens **after** entities have been extracted.
That means that in addition to defining your synonyms, you need to
provide examples of the variations on a synonym as
entities in your training examples so
that Rasa Open Source can learn to pick them up.
:::

### Regular Expression Features

Regular expressions can be used in two different ways:

1. They can be used to support intent classification and entity
extraction when using the RegexFeaturizer component in the pipeline.

2. They can be used to directly extract entities from a user messages
when using the RegexEntityExtractor component in the pipeline.

For example, if your entity has a deterministic structure (like a
zipcode or an email address), you can use a regular expression to ease
detection of that entity (using the RegexFeaturizer) or to directly
extract the entities from the user message (using the
RegexEntityExtractor). For the zipcode example it might look like this:

```yaml
- regex: zipcode
  examples: |
  - [0-9]{5}
```

If you are using regular expressions to directly extract entities using
the RegexEntityExtractor, the name of the regular expression should
match the name of the entity you want to extract.

If you are using the regular expressions for the RegexFeaturizer the
name of the regular expression does not matter. If does not define the
entity nor the intent, it is just a human readable description for you
to remember what this regex is used for and is the title of the
corresponding pattern feature.

If you want to use the RegexFeaturizer you can also use the regex
features to improve the intent classification performance, for example,
by defining a greet clause:

```yaml
- regex: greet
  examples: |
  - hey[^\\s]*
```

Try to create your regular expressions in a way that they match as few
words as possible. E.g. using `hey[^\\s]*` instead of `hey.*`, as the
later one might match the whole message whereas the first one only
matches a single word.

When using the RegexFeaturizer, the regex features for entity extraction
are currently only supported by the `CRFEntityExtractor` and the
`DIETClassifier` component! Hence, other entity extractors, like
`MitieEntityExtractor` or `SpacyEntityExtractor` won't use the generated
features and their presence will not improve entity recognition for
these extractors. Currently, all intent classifiers make use of
available regex features.

:::note

Regex features only define entities when used in combination with the RegexEntityExtractor. Otherwise they  
don't define entities nor intents! They simply provide patterns to
help the classifier recognize entities and related intents. Hence, you
still need to provide intent & entity examples as part of your
training data!
:::

### Lookup Tables

Lookup tables provide a convenient way to supply a list of entity
examples. The format is as follows:

```yaml
- lookup: <lookup table name>
  examples: |
  - <an entity>
  - <another entity>
```

The name of the lookup table is subject to the same constraints as the
name of a regex feature.

When lookup tables are supplied in training data, the contents are
combined into a large regex pattern that looks for exact matches in the
training examples. These regexes match over multiple tokens, so
`lettuce wrap` would match `get me a lettuce wrap ASAP` as
`[0 0 0 1 1 0]`. These regexes are processed identically to the regular
regex patterns directly specified in the training data.

**note**

If you are using lookup tables in combination with the RegexFeaturizer, there must be a few examples of matches  
in your training data. Otherwise the model will not learn to use the
lookup table match features.

**warning**

You have to be careful when you add data to the lookup table.  
For example, if there are false positives or other noise in the table,
this can hurt performance. So make sure your lookup tables contain
clean data.


## Stories

**Stories** are representations of conversations between a user and an AI
assistant. They are used to train the dialogue management model and can help it learn to generalize to unseen conversation paths.

Stories are composed of a name (arbitrary, not used in training), optional metadata (also arbitrary and not used in training) and a list of ``steps``.

For example:

```yaml
stories:
- story: Greet the user
  metadata:
    author: Somebody
    key: value
  steps:
  # list of steps
  - intent: greet
  - action: utter_greet
```

Each step is a dictionary representation of one of the following:

  - A [user message](#user-messages), represented by **intent** and **entities**.
  - An [`or`](#or) statement, which includes two or more user messages under it
  - A bot [action](#actions)
  - A [form](#forms)
  - A [slot was set](#slots) record
  - A [checkpoint](#checkpoints), which connects the story to another story


### User Messages

While writing stories, you do not have to deal with the specific
contents of the messages that the users send. Instead, you can take
advantage of the output from the NLU pipeline, which lets you use just
the combination of an intent and entities to refer to all the possible
messages the users can send to mean the same thing.

User messages follow the format:

```yaml
  steps:
    - intent: <intent name> 
      entities:
      - <entity_name>: <entity value>
```

Intent names can be prefixed with `/` or not; it makes no difference.

For example:

```yaml
  steps:
    - intent: account_balance
      entities:
      - account_type: credit
    - action: action_credit_account_balance
```

It is important to include the entities here as well because the
policies learn to predict the next action based on a *combination* of
both the intent and entities (you can, however, change this behavior
using the [`use_entities`](#use-entities) attribute).


### Actions

All actions executed by the bot are specified with the `action:` key followed
by the name of the action.
While writing stories, you will encounter three types of actions:


1. [**Responses**](#responses): start with `utter_` and send a specific message
   to the user. e.g.

```yaml
    steps:
    - intent: greet
    - action: utter_greet
```

2. [**Retrieval actions**](#retrieval-actions): start with `respond_` and send a message selected by a retrieval model. e.g.

```yaml
    steps:
    - intent: faq
    - action: respond_faq
```

3. [**Custom actions**](#custom-actions): start with `action_`, run arbitrary code and send any number of messages (or none).

```yaml
    steps:
    - intent: feedback
    - action: action_store_feedback
```


### Slots

**[Slots](#slots)** act as the bots memory. Slots are **set** by entities or by custom actions and **referenced** by stories in `slot_was_set` steps. For example.

```yaml
    steps:
    - intent: celebrate_bot
    - slot_was_set: feedback_value
      value: positive
    - action: utter_yay
```

This means the story requires that the current value for the `feedback_value` slot be `positive` in order for the conversation to continue as specified.

:::note
Stories do not **set** slots. The slot must be set by an entity or custom action **before** the `slot_was_set` step.
:::


### Checkpoints

Checkpoints are ways to connect stories together. They can be either the first or the last step in a story. If they are the last step in a storys, that story will be connected to each other story that starts with the checkpoint of the same name when the model is trained.
Here is an example of a story that ends with a checkpoint, and one that starts with the same checkpoint:

```yaml
- story: story_with_a_checkpoint_1
  steps:
  - intent: greet
  - action: utter_greet
  - checkpoint: greet_checkpoint

- story: story_with_a_checkpoint_2
  steps:
  - checkpoint: greet_checkpoint
  - intent: book_flight
  - action: action_book_flight
```

Checkpoints at the beginning of stories can also be conditional on slots being set, for example:

```yaml
- story: story_with_a_conditional_checkpoint
  steps:
  - checkpoint: greet_checkpoint
    # This checkpoint should only apply if slot is set to the specified value
    slots: 
    - context_scenario: holiday
    - holiday_name: thanksgiving
  - intent: greet
  - action: utter_greet_thanksgiving
```


Checkpoints can help simplify your training data and reduce redundancy in it, but **do not overuse them**. Using lots of checkpoints can quickly make your stories hard to understand. It makes sense to use them if a sequence of steps is repeated very often in different stories, but stories without checkpoints are easier to read and write. 

### or

`or` steps are ways to handle multiple intents the same way,
without writing a seperate story for each intent. For example, if you ask the user to confirm something, you might want to treat the `affirm` and `thankyou` intents in the same way. Stories with `or` steps will be converted into multiple
seperate stories at training time. For example, the following story would be converted to two stories at training time:

```yaml
- story: story with OR
  steps:
  - intent: signup_newsletter
  - action: utter_ask_confirm
  - or:
    - intent: affirm
    - intent: thanks
  - action: action_signup_newsletter
```

Just like checkpoints, OR statements can be useful, but if you are using a lot of them, it is probably better to restructure your domain and/or intents.

:::warning
Overusing these features (both checkpoints and OR statements) will slow down training.
:::

## Rules

**[Rules](#rules)** describe parts of conversations that should always follow
the same path and are used to train the [RulePolicy](#rule-policy). Rules
include many of the same steps as stories do, but can also include other
elements like conditions. Read more about rules and their format [here](#rules)

## Responses

Responses are messages the bot will send back to the user. Both [retrieval actions](#retrieval-actions) and [utter actions](#responses) are responses. Both are listed under the `responses` key, and can include text, images and buttons. In this example, `utter_greet` and 
`utter_cheer_up` are utter actions, while `faq/language` is a retrieval
action: 

```yaml
responses:
  utter_greet:
  - text: "Hey! How are you?"
    buttons:
    - title: "great"
      payload: "/react_positive"
    - title: "super sad"
      payload: "/react_negative"
  utter_cheer_up:
  - text: "Here is something to cheer you up:"
    image: "https://i.imgur.com/nGF1K8f.jpg"
  faq/language:
  - text: "I only speak English for now!"
```

Read more about responses and their format on the [domains page](../core/domains#responses)

## Test Conversations

Test conversations combine both NLU and Core training data into a end-to-end story for evaluation. 

:::warning
This format is only used for end-to-end evaluation and cannot be used for training.
:::

Test conversations are listed under the `e2e_tests` key. 
Their format is very similar to the [story](#stories) format,
except that user message steps can include a `user` key which specifies the actual text and entity annotation of the user message. 

Here's an example of a test conversation:

```yaml
e2e_tests:
- story: A basic end-to-end test
  steps:
  - user: |
     hello
    intent: greet
  - action: utter_ask_howcanhelp
  - user: |
     show me [chinese]{"entity": "cuisine"} restaurants
    intent: inform
  - action: utter_ask_location
  - user: |
     in [Paris]{"entity": "location"}
    intent: inform
  - action: utter_ask_price
```