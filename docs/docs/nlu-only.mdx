---
id: nlu-only
sidebar_label: Using NLU Only
title: Using NLU Only
abstract: Find out how to use only Rasa NLU as a standalone NLU service for your chatbot or virtual assistant.
---

If you want to use Rasa only as an NLU component, you can!

## Training NLU-only models

To train an NLU model only, run:

```bash
rasa train nlu
```

This will look for NLU training data files in the ``data/`` directory
and saves a trained model in the ``models/`` directory.
The name of the model will start with ``nlu-``.


## Testing your NLU model on the command line

To try out your NLU model on the command line, run the following command:

```bash
rasa shell nlu
```

This will start the rasa shell and ask you to type in a message to test.
You can keep typing in as many messages as you like.

Alternatively, you can leave out the ``nlu`` argument and pass in an nlu-only model directly:

```bash
rasa shell -m models/nlu-20190515-144445.tar.gz
```

## Running an NLU server

To start a server with your NLU model, pass in the model name at runtime:

```bash
rasa run --enable-api -m models/nlu-20190515-144445.tar.gz
```

You can then request predictions from your model using the ``/model/parse`` endpoint.
To do this, run:

```bash
curl localhost:5005/model/parse -d '{"text":"hello"}'
```

## Connecting to an NLU server


You can connect a Rasa dialogue management only server with a separately running NLU server
by adding the connection details to the dialogue management server's endpoint configuration file:

```yaml-rasa title="endpoints.yml"
nlu:
    url: "http://<your nlu host>:<your nlu port>"
    token: <token>  # [optional]
    token_name: <name of the token> # [optional] (default: token)
```

The `token` and `token_name` refer to optional [authentication paramenters](./http-api.mdx#token-based-auth).

The dialogue management server should serve a model that does not include an NLU model.
To obtain a dialogue management only model, train a model with `rasa train core` or use 
`rasa train` but exclude all NLU data.

When the dialogue management server receives a message, it will [send a request](https://rasa.com/docs/rasa/pages/http-api#operation/parseModelMessage) to 
`http://<your nlu host>:<your nlu port>/model/parse` and use the parsing information returned.

Note that you should **not** use the same endpoint configuration file for the NLU server as for the dialogue management server, since
the `nlu` endpoint refers back to the NLU server itself.

If you are implementing a custom NLU server (i.e. not Rasa NLU), your server should provide a `/model/parse` endpoint that responds to requests in the same 
format as a Rasa NLU server does.
